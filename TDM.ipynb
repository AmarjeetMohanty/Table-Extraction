{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "import os\n",
    "from transformers import DetrImageProcessor, TableTransformerForObjectDetection\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from skimage.measure import label, regionprops\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(\"The folder does not exist.\")\n",
    "\n",
    "    file_count = 0\n",
    "\n",
    "    for _, _, files in os.walk(folder_path):\n",
    "        file_count += len(files)\n",
    "\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the folder: 580\n"
     ]
    }
   ],
   "source": [
    "folder_path =\"png_ano_test\"\n",
    "num_files = count_files_in_folder(folder_path)\n",
    "print(\"Number of files in the folder:\", num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the folder: 580\n"
     ]
    }
   ],
   "source": [
    "folder_path =\"test_img\"\n",
    "num_files = count_files_in_folder(folder_path)\n",
    "print(\"Number of files in the folder:\", num_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is a imbalance in the number of masked files and actual images . We have to introduce blank png files in the png_ano_test folder accurately named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_additional_files_ignore_extension(folder1_path, folder2_path):\n",
    "    if not os.path.exists(folder1_path) or not os.path.exists(folder2_path):\n",
    "        raise FileNotFoundError(\"One or both folders do not exist.\")\n",
    "\n",
    "    folder1_files = set([os.path.splitext(file)[0] for file in os.listdir(folder1_path)])\n",
    "    folder2_files = set([os.path.splitext(file)[0] for file in os.listdir(folder2_path)])\n",
    "\n",
    "    additional_files_in_folder1 = folder1_files - folder2_files\n",
    "\n",
    "    return additional_files_in_folder1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional files in folder 1 but not in folder 2 (ignoring extensions):\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "folder1_path = \"test_img\"\n",
    "folder2_path = \"png_ano_test\"\n",
    "\n",
    "additional_files = find_additional_files_ignore_extension(folder1_path, folder2_path)\n",
    "print(\"Additional files in folder 1 but not in folder 2 (ignoring extensions):\")\n",
    "\n",
    "print(len(additional_files))\n",
    "for file in additional_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blank_png_files(folder_path, filenames):\n",
    "    if not os.path.exists(folder_path):\n",
    "        raise FileNotFoundError(\"The folder does not exist.\")\n",
    "\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(folder_path, filename + \".png\")\n",
    "        blank_image = Image.new(\"RGB\", (512, 512), color=(0, 0, 0))  # Create a 1x1 white image that is appropiately scaled\n",
    "        blank_image.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing files found in the second folder.\n"
     ]
    }
   ],
   "source": [
    "if additional_files:\n",
    "    create_blank_png_files(folder2_path, additional_files)\n",
    "    print(f\"Blank PNG files created in {folder2_path} for missing files.\")\n",
    "else:\n",
    "    print(\"No missing files found in the second folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'train_img'  # Path to the dataset folder containing images\n",
    "masked_dataset_path = 'png_ano_train'  # Path to the already masked dataset folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model and feature extractor\n",
    "model = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "feature_extractor = DetrImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for detection\n",
    "detection_threshold = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoUScore(predicted_array, ground_truth_array):\n",
    "    intersection = np.logical_and(predicted_array, ground_truth_array)\n",
    "    union = np.logical_or(predicted_array,ground_truth_array)\n",
    "\n",
    "    intersection_area = np.sum(intersection)\n",
    "    union_area = np.sum(union)\n",
    "\n",
    "    if union_area==0:\n",
    "        return 0\n",
    "    else :\n",
    "        return intersection_area/union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images done....\n",
      "100  images done....\n",
      "200  images done....\n",
      "300  images done....\n",
      "400  images done....\n",
      "500  images done....\n",
      "600  images done....\n",
      "700  images done....\n",
      "800  images done....\n",
      "900  images done....\n",
      "1000  images done....\n",
      "1100  images done....\n",
      "1200  images done....\n",
      "1300  images done....\n",
      "1400  images done....\n",
      "1500  images done....\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation metrics\n",
    "y_true = []  # Ground truth labels\n",
    "y_pred = []  # Predicted labels\n",
    "counter = 0\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    \n",
    "    # Load the dataset image (JPG)\n",
    "    image_path = os.path.join(dataset_path, file_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Load the corresponding masked image (PNG)\n",
    "    masked_image_path = os.path.join(masked_dataset_path, file_name[:-4] + \".png\")  # Assuming the filenames are consistent\n",
    "    masked_image = Image.open(masked_image_path)\n",
    "    \n",
    "    # Preprocess the dataset image\n",
    "    width, height = image.size\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Perform table detection\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    \n",
    "    # Post-process the detection results\n",
    "    width, height = image.size\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=detection_threshold, target_sizes=[(height, width)])[0]\n",
    "    \n",
    "    # Convert the results to binary masks\n",
    "    pred_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for box in results['boxes']:\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "        xmin, xmax = int(xmin), int(xmax)\n",
    "        ymin, ymax = int(ymin), int(ymax)\n",
    "        pred_mask[ymin:ymax, xmin:xmax] = 1\n",
    "    \n",
    "    \n",
    "    # Convert the masked image to binary mask\n",
    "    true_mask = np.array(masked_image)\n",
    "    true_mask = true_mask*255\n",
    "    temp_data = Image.fromarray(true_mask).convert(\"L\")\n",
    "    true_mask = np.array(temp_data)\n",
    "    true_mask = np.where(true_mask == 0, 1, 0)\n",
    "    # Compare the binary masks\n",
    "\n",
    "    y_true.extend(true_mask.flatten())\n",
    "    y_pred.extend(pred_mask.flatten())\n",
    "    \n",
    "    if counter%100 == 0:\n",
    "        print(counter,\" images done....\") \n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393740288, 393740288)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "iouscore = IoUScore(y_true,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9604721881196078\n",
      "Recall: 0.6736312502443701\n",
      "F1 Score: 0.791876530846445\n",
      "Accuracy: 0.9304003886947937\n",
      "IoU Score: 0.655459935234315\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"IoU Score: {iouscore}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = np.empty(0)\n",
    "keys = []\n",
    "values = []\n",
    "ioudict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images done....\n",
      "100  images done....\n",
      "200  images done....\n",
      "300  images done....\n",
      "400  images done....\n",
      "500  images done....\n",
      "600  images done....\n",
      "700  images done....\n",
      "800  images done....\n",
      "900  images done....\n",
      "1000  images done....\n",
      "1100  images done....\n",
      "1200  images done....\n",
      "1300  images done....\n",
      "1400  images done....\n",
      "1500  images done....\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "destination_path = \"train_directory\"\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    \n",
    "    y_true = []\n",
    "    y_test = []\n",
    "    # Load the dataset image (JPG)\n",
    "    image_path = os.path.join(dataset_path, file_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Load the corresponding masked image (PNG)\n",
    "    masked_image_path = os.path.join(masked_dataset_path, file_name[:-4] + \".png\")  # Assuming the filenames are consistent\n",
    "    masked_image = Image.open(masked_image_path)\n",
    "    \n",
    "    # Preprocess the dataset image\n",
    "    width, height = image.size\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Perform table detection\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    \n",
    "    # Post-process the detection results\n",
    "    width, height = image.size\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=detection_threshold, target_sizes=[(height, width)])[0]\n",
    "    \n",
    "    # Convert the results to binary masks\n",
    "    pred_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for box in results['boxes']:\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "        xmin, xmax = int(xmin), int(xmax)\n",
    "        ymin, ymax = int(ymin), int(ymax)\n",
    "        pred_mask[ymin:ymax, xmin:xmax] = 1\n",
    "    \n",
    "    \n",
    "    # Convert the masked image to binary mask\n",
    "    true_mask = np.array(masked_image)\n",
    "    true_mask = true_mask*255\n",
    "    temp_data = Image.fromarray(true_mask).convert(\"L\")\n",
    "    true_mask = np.array(temp_data)\n",
    "    true_mask = np.where(true_mask == 0, 1, 0)\n",
    "\n",
    "    np.append(all_values,IoUScore(pred_mask,true_mask))\n",
    "    if IoUScore(pred_mask,true_mask)<0.8:\n",
    "        filename = os.path.basename(image_path)\n",
    "        destination_file_path = os.path.join(destination_path, filename)\n",
    "        with open(source_path, 'rb') as source_file, open(destination_file_path, 'wb') as dest_file:\n",
    "            dest_file.write(source_file.read())\n",
    "        keys.append(image_path)\n",
    "        values.append(IoUScore(pred_mask,true_mask))\n",
    "    \n",
    "    if counter%100 == 0:\n",
    "        print(counter,\" images done....\") \n",
    "    \n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\debam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(keys)):\n",
    "    ioudict[keys[i]] = values[i]\n",
    "\n",
    "len(ioudict),np.mean(all_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'test_img'  # Path to the dataset folder containing images\n",
    "masked_dataset_path = 'png_ano_test'  # Path to the already masked dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "\n",
    "y_true_array = []  # ground truth value\n",
    "y_pred_array = []  # predicted value\n",
    "\n",
    "y_true = np.array(y_true_array)\n",
    "y_pred = np.array(y_pred_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images done....\n",
      "100  images done....\n",
      "200  images done....\n",
      "300  images done....\n",
      "400  images done....\n",
      "500  images done....\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    \n",
    "    # Load the dataset image (JPG)\n",
    "    image_path = os.path.join(dataset_path, file_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Load the corresponding masked image (PNG)\n",
    "    masked_image_path = os.path.join(masked_dataset_path, file_name[:-4] + \".png\")  # Assuming the filenames are consistent\n",
    "    masked_image = Image.open(masked_image_path)\n",
    "    \n",
    "    # Preprocess the dataset image\n",
    "    width, height = image.size\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Perform table detection\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    \n",
    "    # Post-process the detection results\n",
    "    width, height = image.size\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=detection_threshold, target_sizes=[(height, width)])[0]\n",
    "    \n",
    "    # Convert the results to binary masks\n",
    "    pred_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for box in results['boxes']:\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "        xmin, xmax = int(xmin), int(xmax)\n",
    "        ymin, ymax = int(ymin), int(ymax)\n",
    "        pred_mask[ymin:ymax, xmin:xmax] = 1\n",
    "    \n",
    "    \n",
    "    # Convert the masked image to binary mask\n",
    "    true_mask = np.array(masked_image)\n",
    "    true_mask = true_mask*255\n",
    "    temp_data = Image.fromarray(true_mask).convert(\"L\")\n",
    "    true_mask = np.array(temp_data)\n",
    "    true_mask = np.where(true_mask == 0, 1, 0)\n",
    "    # Compare the binary masks\n",
    "\n",
    "    y_true = np.append(y_true, true_mask.flatten())\n",
    "    y_pred = np.append(y_pred, pred_mask.flatten())\n",
    "    \n",
    "    if counter%100 == 0:\n",
    "        print(counter,\" images done....\") \n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "iouscore = IoUScore(y_true,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9661867233931971\n",
      "Recall: 0.6209830688522506\n",
      "F1 Score: 0.7560446267417663\n",
      "Accuracy: 0.913078025291706\n",
      "IoU Score: 0.607774718446285\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"IoU Score: {iouscore}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = np.empty(0)\n",
    "keys = []\n",
    "values = []\n",
    "ioudict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images done....\n",
      "100  images done....\n",
      "200  images done....\n",
      "300  images done....\n",
      "400  images done....\n",
      "500  images done....\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "destination_path = \"test_directory\"\n",
    "for file_name in os.listdir(dataset_path):    \n",
    "    y_true = []\n",
    "    y_test = []\n",
    "    # Load the dataset image (JPG)\n",
    "    image_path = os.path.join(dataset_path, file_name)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # Load the corresponding masked image (PNG)\n",
    "    masked_image_path = os.path.join(masked_dataset_path, file_name[:-4] + \".png\")  # Assuming the filenames are consistent\n",
    "    masked_image = Image.open(masked_image_path)\n",
    "    \n",
    "    # Preprocess the dataset image\n",
    "    width, height = image.size\n",
    "    encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Perform table detection\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    \n",
    "    # Post-process the detection results\n",
    "    width, height = image.size\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=detection_threshold, target_sizes=[(height, width)])[0]\n",
    "    \n",
    "    # Convert the results to binary masks\n",
    "    pred_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    for box in results['boxes']:\n",
    "        xmin, ymin, xmax, ymax = box.tolist()\n",
    "        xmin, xmax = int(xmin), int(xmax)\n",
    "        ymin, ymax = int(ymin), int(ymax)\n",
    "        pred_mask[ymin:ymax, xmin:xmax] = 1\n",
    "    \n",
    "    \n",
    "    # Convert the masked image to binary mask\n",
    "    true_mask = np.array(masked_image)\n",
    "    true_mask = true_mask*255\n",
    "    temp_data = Image.fromarray(true_mask).convert(\"L\")\n",
    "    true_mask = np.array(temp_data)\n",
    "    true_mask = np.where(true_mask == 0, 1, 0)\n",
    "\n",
    "    np.append(all_values,IoUScore(pred_mask,true_mask))\n",
    "    if IoUScore(pred_mask,true_mask)<0.8:\n",
    "        filename = os.path.basename(image_path)\n",
    "        destination_file_path = os.path.join(destination_path, filename)\n",
    "        with open(source_path, 'rb') as source_file, open(destination_file_path, 'wb') as dest_file:\n",
    "            dest_file.write(source_file.read())        \n",
    "        \n",
    "        keys.append(image_path)\n",
    "        values.append(IoUScore(pred_mask,true_mask))\n",
    "    \n",
    "    if counter%100 == 0:\n",
    "        print(counter,\" images done....\") \n",
    "    \n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\debam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\debam\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(263, nan)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(keys)):\n",
    "    ioudict[keys[i]] = values[i]\n",
    "\n",
    "len(ioudict),np.mean(all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
